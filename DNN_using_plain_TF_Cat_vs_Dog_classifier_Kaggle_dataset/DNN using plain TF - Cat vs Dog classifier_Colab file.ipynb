{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/selvam-learn/Cat-Dog-Classifier/blob/master/DNN_using_plain_TF_Cat_vs_Dog_classifier_Kaggle_dataset/DNN%20using%20plain%20TF%20-%20Cat%20vs%20Dog%20classifier_Colab%20file.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8xkS3MVSpU73"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import time\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers import fully_connected, l2_regularizer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mini_dataset(index):\n",
    "    filename_prefix = 'datasets/dog_vs_cat_normalized_dataset_kaggle_128px_'\n",
    "    filename = filename_prefix + str(index) + \".h5\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "    \n",
    "        #print(list(f.keys()))\n",
    "        x_mini_data = None\n",
    "        y_mini_data = None\n",
    "        \n",
    "        x_mini_data = f[\"input_data\"][:]\n",
    "        y_mini_data = f[\"input_labels\"][:]\n",
    "        \n",
    "    return x_mini_data, y_mini_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_shuffled_indices(start_value, last_value):\n",
    "    \n",
    "    temp = np.arange(start_value, last_value)\n",
    "    shuffle(temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_random_mini_batches(X, Y, n_classes = 2, mini_batch_size = 32):\n",
    "    \n",
    "    m = X.shape[0] # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    #print(\"Shape of X =\", X.shape)\n",
    "    #print(\"Shape of Y =\", Y.shape)\n",
    "    \n",
    "    #Reshaping to convert Y to a 2D array from a rank one array\n",
    "    Y = Y.reshape(Y.shape[0], 1)\n",
    "    \n",
    "    #Shuffle the data in each of the mini batch\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation, :]\n",
    "    shuffled_Y = Y[permutation, :]\n",
    "    \n",
    "    n_mini_batches = math.ceil(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(n_mini_batches):\n",
    "        \n",
    "        start_pos = k * mini_batch_size\n",
    "        end_pos = min(start_pos + mini_batch_size, m)\n",
    "        \n",
    "        mini_batch_X = shuffled_X[start_pos : end_pos, :]\n",
    "        mini_batch_Y = shuffled_Y[start_pos : end_pos, :]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i56i0MpqpU8U"
   },
   "source": [
    "### Build the DNN using plain TensorFlow\n",
    "\n",
    "**Step 1 - Code the individual ops in the computation graph**\n",
    "- Create Placeholders for X, Y\n",
    "- Create the nn_model - all the layers and initialize them\n",
    "- Compute the cost\n",
    "- Create the optimizer to minimize the cost\n",
    "- Evaluate the model\n",
    "\n",
    "**Step 2 - Build the computation graph**\n",
    "- Combine all the steps in Step 1 to build the computation graph\n",
    "- Initialize the variables\n",
    "- Create a Saver object to save the learnt parameters after the model is trained\n",
    "\n",
    "**Step 3 - Execute the graph**\n",
    "- Create mini batches so that gradient descent works on these mini batches for every step instead of all instances\n",
    "- Train the model for a given number of epochs\n",
    "- Print the cost, train accuracy & test accuracy at regular interval of epochs\n",
    "- Plot the training error (cost) vs epochs\n",
    "- Save the parameters\n",
    "\n",
    "**Step 4 - Predict for any data**\n",
    "- Build a method to pass random data for the model to predict based on the parameters learnt through training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oq2WIyiCpU8V"
   },
   "source": [
    "### Create the placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AkBHP2R4pU8X"
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_inputs):\n",
    "    '''\n",
    "    n_inputs - A scalar containing the number of input features\n",
    "    '''\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = 'X')\n",
    "    Y = tf.placeholder(tf.float32, shape = (None, 1), name = 'Y')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HoJ-w6NMpU8a"
   },
   "source": [
    "### Create the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0iig8mn_pU8c"
   },
   "outputs": [],
   "source": [
    "def nn_model(X, n_neurons):\n",
    "    '''\n",
    "    X - input Tensor X\n",
    "    n_neurons - A scalar containing the number of neurons in each layer including both hidden layers and output layer \n",
    "    '''\n",
    "    #with arg_scope([fully_connected], weights_regularizer = l2_regularizer(scale = 0.01)):\n",
    "    hidden_layer_1 = fully_connected(X, n_neurons['hidden_layer_1'], scope = 'hidden_layer_1')\n",
    "    hidden_layer_2 = fully_connected(hidden_layer_1, n_neurons['hidden_layer_2'], scope = 'hidden_layer_2')\n",
    "    hidden_layer_3 = fully_connected(hidden_layer_2, n_neurons['hidden_layer_3'], scope = 'hidden_layer_3')\n",
    "    hidden_layer_4 = fully_connected(hidden_layer_3, n_neurons['hidden_layer_4'], scope = 'hidden_layer_4')\n",
    "    hidden_layer_5 = fully_connected(hidden_layer_4, n_neurons['hidden_layer_5'], scope = 'hidden_layer_5')\n",
    "    logits = fully_connected(hidden_layer_3, n_neurons['output_layer'], activation_fn = None, scope = 'output_layer')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZMtdnd7pU8f"
   },
   "source": [
    "### Compute the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iwvRAcarpU8g"
   },
   "outputs": [],
   "source": [
    "def compute_cost(labels, logits):\n",
    "    '''\n",
    "    labels - label tensor Y\n",
    "    logits - Tensor containing the values of the output layer before passing to the activation function\n",
    "    '''\n",
    "    \n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits)\n",
    "    cost = tf.reduce_mean(cross_entropy, name = 'cost')\n",
    "    #base_cost = tf.reduce_mean(cross_entropy)\n",
    "    #reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #cost = tf.add_n([base_cost] + reg_losses, name = 'cost')\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAWyNQI6pU8m"
   },
   "source": [
    "### Create the optimizer and the training operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xk2mXeZ6pU8o"
   },
   "outputs": [],
   "source": [
    "def optimizer(learning_rate, cost):\n",
    "    '''\n",
    "    learning_rate - A scalar value containing the learning rate for the backpropagation step\n",
    "    cost - Overall cost from the forward propagation step for one set of mini batch instance\n",
    "    '''\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(cost)\n",
    "    \n",
    "    return training_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnft-gRwpU8r"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "We will use accuracy as the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kaxqAWcmpU8r"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(logits, Y):\n",
    "    '''\n",
    "    logits - An array containing the values from the output layer\n",
    "    Y - An array containing the labels\n",
    "    '''\n",
    "    \n",
    "    #Compute the probability using the sigmoid function\n",
    "    y_pred = tf.nn.sigmoid(logits)\n",
    "    #Convert it to 0 or 1 class based on the probability and cast it to integer\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.int64)\n",
    "    #y_pred = tf.cast(tf.round(y_pred), tf.int64)\n",
    "    \n",
    "    #Create a boolean tensor by comparing the model prediction against the labels\n",
    "    correct_prediction = tf.equal(y_pred, tf.cast(Y, tf.int64))\n",
    "    #Compute the accuracy across all the instances\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-SeFuNupU8v"
   },
   "source": [
    "### Build the computation graph & execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uUyeq938pU8w"
   },
   "outputs": [],
   "source": [
    "def train_model(n_neurons, n_inputs, learning_rate = 0.01, mini_batch_size = 32, n_epochs = 50, print_cost = False):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    #Declare and initialize the required variables\n",
    "    costs = []\n",
    "    \n",
    "    #Create Placeholder\n",
    "    X, Y = create_placeholders(n_inputs)\n",
    "    \n",
    "    #Create the nn_model\n",
    "    logits = nn_model(X, n_neurons) \n",
    "    \n",
    "    #Compute the cost\n",
    "    cost = compute_cost(Y, logits)\n",
    "    \n",
    "    #Optimize the cost using Gradient Descent Optimizer\n",
    "    training_op = optimizer(learning_rate, cost)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    accuracy = evaluate_model(logits, Y)\n",
    "    \n",
    "    #Initialize the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #Create the Saver object\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Execute the Graph - Train the model\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        \n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            n_mini_batches = 0\n",
    "            epoch_cost = 0\n",
    "            \n",
    "            tic = time.time()\n",
    "            \n",
    "            file_indices = get_shuffled_indices(1, 26)\n",
    "            for j in file_indices:\n",
    "                X_mini = None\n",
    "                Y_mini = None\n",
    "                X_mini, Y_mini = load_mini_dataset(j)\n",
    "                \n",
    "                mini_batches = None\n",
    "                mini_batches = create_random_mini_batches(X_mini, Y_mini, mini_batch_size = mini_batch_size)\n",
    "            \n",
    "                for mini_batch in mini_batches:\n",
    "                    n_mini_batches += 1\n",
    "                    (X_mini_batch, Y_mini_batch) = mini_batch\n",
    "                    _, mini_batch_cost = sess.run([training_op, cost], feed_dict = {X: X_mini_batch, Y: Y_mini_batch})\n",
    "\n",
    "                    epoch_cost += mini_batch_cost\n",
    "            \n",
    "            toc = time.time()\n",
    "            print('Epoch', epoch, 'took', ((toc-tic)*1000), 'ms')\n",
    "            \n",
    "            epoch_cost = epoch_cost / n_mini_batches\n",
    "            train_accuracy = accuracy.eval(feed_dict = {X: X_mini_batch, Y: Y_mini_batch})\n",
    "            #cval_accuracy = accuracy.eval(feed_dict = {X: X_cval, Y: Y_cval})\n",
    "            \n",
    "            if print_cost and epoch % 2 == 0:\n",
    "                print('At epoch', epoch, 'Cost =', epoch_cost, '| Train Accuracy =', train_accuracy)\n",
    "            \n",
    "            if epoch % 2 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "            \n",
    "        saver_path = saver.save(sess, './my_model_final.ckpt')\n",
    "        \n",
    "    #print('Final - Train Accuracy =', train_accuracy, '| CVal Accuracy =', cval_accuracy)\n",
    "    print('Final - Train Accuracy =', train_accuracy)\n",
    "        \n",
    "    plt.plot(costs)\n",
    "    plt.xlabel('# of Epochs')\n",
    "    plt.ylabel('Training Error - Cost')\n",
    "    plt.title('Training Error Vs Epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    return saver_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDvKIWNHpU8z",
    "outputId": "d92a58cd-70c0-4664-ccc6-39c02bb3443b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_neurons = {'hidden_layer_1': 50,\n",
    "             'hidden_layer_2': 50,\n",
    "             'hidden_layer_3': 50,\n",
    "             'hidden_layer_4': 50,\n",
    "             'hidden_layer_5': 30,\n",
    "             'output_layer': 1}\n",
    "n_input_features = 49152\n",
    "train_model(n_neurons, n_input_features, learning_rate = 0.01, n_epochs = 200, mini_batch_size = 32,\n",
    "            print_cost = True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "DNN using plain TF - Cat vs Dog classifier.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
