{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers import fully_connected, l2_regularizer\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from util import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape (22500, 128, 128, 3)\n",
      "Train Y shape (22500, 1)\n",
      "CVal X shape (2500, 128, 128, 3)\n",
      "CVal Y shape (2500, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train, X_cval_orig, Y_cval = load_dataset('datasets/dog_vs_cat_dataset_kaggle_128px.h5')\n",
    "\n",
    "print('Train X shape', X_train_orig.shape)\n",
    "print('Train Y shape', Y_train.shape)\n",
    "print('CVal X shape', X_cval_orig.shape)\n",
    "print('CVal Y shape', Y_cval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the DNN using plain TensorFlow\n",
    "\n",
    "**Step 1 - Code the individual ops in the computation graph**\n",
    "- Create Placeholders for X, Y\n",
    "- Create the nn_model - all the layers and initialize them\n",
    "- Compute the cost\n",
    "- Create the optimizer to minimize the cost\n",
    "- Evaluate the model\n",
    "\n",
    "**Step 2 - Build the computation graph**\n",
    "- Combine all the steps in Step 1 to build the computation graph\n",
    "- Initialize the variables\n",
    "- Create a Saver object to save the learnt parameters after the model is trained\n",
    "\n",
    "**Step 3 - Execute the graph**\n",
    "- Create mini batches so that gradient descent works on these mini batches for every step instead of all instances\n",
    "- Train the model for a given number of epochs\n",
    "- Print the cost, train accuracy & test accuracy at regular interval of epochs\n",
    "- Plot the training error (cost) vs epochs\n",
    "- Save the parameters\n",
    "\n",
    "**Step 4 - Predict for any data**\n",
    "- Build a method to pass random data for the model to predict based on the parameters learnt through training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_inputs):\n",
    "    '''\n",
    "    n_inputs - A scalar containing the number of input features\n",
    "    '''\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = 'X')\n",
    "    Y = tf.placeholder(tf.float32, shape = (None, 1), name = 'Y')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(X, n_neurons):\n",
    "    '''\n",
    "    X - input Tensor X\n",
    "    n_neurons - A scalar containing the number of neurons in each layer including both hidden layers and output layer \n",
    "    '''\n",
    "    #with arg_scope([fully_connected], weights_regularizer = l2_regularizer(scale = 0.01)):\n",
    "    hidden_layer_1 = fully_connected(X, n_neurons['hidden_layer_1'], scope = 'hidden_layer_1')\n",
    "    hidden_layer_2 = fully_connected(hidden_layer_1, n_neurons['hidden_layer_2'], scope = 'hidden_layer_2')\n",
    "    hidden_layer_3 = fully_connected(hidden_layer_2, n_neurons['hidden_layer_3'], scope = 'hidden_layer_3')\n",
    "    hidden_layer_4 = fully_connected(hidden_layer_3, n_neurons['hidden_layer_4'], scope = 'hidden_layer_4')\n",
    "    hidden_layer_5 = fully_connected(hidden_layer_4, n_neurons['hidden_layer_5'], scope = 'hidden_layer_5')\n",
    "    logits = fully_connected(hidden_layer_3, n_neurons['output_layer'], activation_fn = None, scope = 'output_layer')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(labels, logits):\n",
    "    '''\n",
    "    labels - label tensor Y\n",
    "    logits - Tensor containing the values of the output layer before passing to the activation function\n",
    "    '''\n",
    "    \n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits)\n",
    "    cost = tf.reduce_mean(cross_entropy, name = 'cost')\n",
    "    #base_cost = tf.reduce_mean(cross_entropy)\n",
    "    #reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #cost = tf.add_n([base_cost] + reg_losses, name = 'cost')\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the optimizer and the training operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizer(learning_rate, cost):\n",
    "    '''\n",
    "    learning_rate - A scalar value containing the learning rate for the backpropagation step\n",
    "    cost - Overall cost from the forward propagation step for one set of mini batch instance\n",
    "    '''\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(cost)\n",
    "    \n",
    "    return training_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "We will use accuracy as the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(logits, Y):\n",
    "    '''\n",
    "    logits - An array containing the values from the output layer\n",
    "    Y - An array containing the labels\n",
    "    '''\n",
    "    \n",
    "    #Compute the probability using the sigmoid function\n",
    "    y_pred = tf.nn.sigmoid(logits)\n",
    "    #Convert it to 0 or 1 class based on the probability and cast it to integer\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.int64)\n",
    "    #y_pred = tf.cast(tf.round(y_pred), tf.int64)\n",
    "    \n",
    "    #Create a boolean tensor by comparing the model prediction against the labels\n",
    "    correct_prediction = tf.equal(y_pred, tf.cast(Y, tf.int64))\n",
    "    #Compute the accuracy across all the instances\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the computation graph & execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_cval, Y_cval, n_neurons, \n",
    "               learning_rate = 0.01, mini_batch_size = 64, n_epochs = 50, print_cost = False):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    #Declare and initialize the required variables\n",
    "    (n_samples, n_inputs) = X_train.shape\n",
    "    costs = []\n",
    "    \n",
    "    #Create Placeholder\n",
    "    X, Y = create_placeholders(n_inputs)\n",
    "    \n",
    "    #Create the nn_model\n",
    "    logits = nn_model(X, n_neurons) \n",
    "    \n",
    "    #Compute the cost\n",
    "    cost = compute_cost(Y, logits)\n",
    "    \n",
    "    #Optimize the cost using Gradient Descent Optimizer\n",
    "    training_op = optimizer(learning_rate, cost)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    accuracy = evaluate_model(logits, Y)\n",
    "    \n",
    "    #Initialize the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #Create the Saver object\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Execute the Graph - Train the model\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        \n",
    "        n_mini_batches = int(n_samples / mini_batch_size)\n",
    "        \n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            epoch_cost = 0\n",
    "            mini_batches = create_random_mini_batches(X_train, Y_train, mini_batch_size = mini_batch_size, \n",
    "                                                      one_hot_vector_flag = False)\n",
    "            \n",
    "            for mini_batch in mini_batches:\n",
    "                (X_mini_batch, Y_mini_batch) = mini_batch\n",
    "                _, mini_batch_cost = sess.run([training_op, cost], feed_dict = {X: X_mini_batch, Y: Y_mini_batch})\n",
    "                \n",
    "                epoch_cost += mini_batch_cost\n",
    "            \n",
    "            epoch_cost = epoch_cost / n_mini_batches\n",
    "            train_accuracy = accuracy.eval(feed_dict = {X: X_train, Y: Y_train})\n",
    "            cval_accuracy = accuracy.eval(feed_dict = {X: X_cval, Y: Y_cval})\n",
    "            \n",
    "            if print_cost and epoch % 20 == 0:\n",
    "                print('At epoch', epoch, 'Cost =', epoch_cost, '| Train Accuracy =', train_accuracy, \n",
    "                      '| CVal Accuracy =', cval_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "            \n",
    "        saver_path = saver.save(sess, './my_model_final.ckpt')\n",
    "        \n",
    "    print('Final - Train Accuracy =', train_accuracy, '| CVal Accuracy =', cval_accuracy)\n",
    "        \n",
    "    plt.plot(costs)\n",
    "    plt.xlabel('# of Epochs (in tens)')\n",
    "    plt.ylabel('Training Error - Cost')\n",
    "    plt.title('Training Error Vs Epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    return saver_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 20 Cost = 0.695145832677 | Train Accuracy = 0.500267 | CVal Accuracy = 0.498\n",
      "At epoch 40 Cost = 0.69525329221 | Train Accuracy = 0.500267 | CVal Accuracy = 0.498\n",
      "At epoch 60 Cost = 0.695372550406 | Train Accuracy = 0.500267 | CVal Accuracy = 0.498\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-18f0a75beca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m              'output_layer': 1}\n\u001b[0;32m      7\u001b[0m train_model(X_train, Y_train, X_cval, Y_cval, n_neurons, learning_rate = 0.01, n_epochs = 200, mini_batch_size = 64,\n\u001b[1;32m----> 8\u001b[1;33m             print_cost = True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-a269a97c14f2>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, Y_train, X_cval, Y_cval, n_neurons, learning_rate, mini_batch_size, n_epochs, print_cost)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mepoch_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_cost\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_mini_batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mcval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_cval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_cval\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\ProgramFiles\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m     \"\"\"\n\u001b[1;32m--> 710\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\ProgramFiles\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5178\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5179\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5180\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\ProgramFiles\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\ProgramFiles\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mD:\\Softwares\\ProgramFiles\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_neurons = {'hidden_layer_1': 50,\n",
    "             'hidden_layer_2': 50,\n",
    "             'hidden_layer_3': 50,\n",
    "             'hidden_layer_4': 50,\n",
    "             'hidden_layer_5': 30,\n",
    "             'output_layer': 1}\n",
    "train_model(X_train, Y_train, X_cval, Y_cval, n_neurons, learning_rate = 0.01, n_epochs = 200, mini_batch_size = 64,\n",
    "            print_cost = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
